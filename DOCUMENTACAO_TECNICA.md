# Documenta√ß√£o T√©cnica - Adam Sandler News Agent

## Vis√£o Geral

O Adam Sandler News Agent √© um sistema de agrega√ß√£o de not√≠cias que busca, filtra e envia por email not√≠cias relevantes sobre o ator Adam Sandler. O sistema utiliza web scraping para extrair not√≠cias de diferentes fontes e aplica filtros de relev√¢ncia baseados em palavras-chave.

## Arquitetura do Sistema

### Estrutura de Pastas

```
src/
‚îú‚îÄ‚îÄ domain/                 # Regras de neg√≥cio e entidades
‚îÇ   ‚îú‚îÄ‚îÄ entities/          # Entidades do dom√≠nio (News, NewsSource, Report)
‚îÇ   ‚îú‚îÄ‚îÄ repositories/      # Interfaces dos reposit√≥rios
‚îÇ   ‚îî‚îÄ‚îÄ services/          # Servi√ßos de dom√≠nio
‚îú‚îÄ‚îÄ application/           # Casos de uso e servi√ßos de aplica√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ use_cases/        # Casos de uso principais
‚îÇ   ‚îî‚îÄ‚îÄ services/         # Servi√ßos de aplica√ß√£o
‚îú‚îÄ‚îÄ infrastructure/       # Implementa√ß√µes t√©cnicas
‚îÇ   ‚îú‚îÄ‚îÄ web_scraping/     # Scrapers e reposit√≥rio de not√≠cias
‚îÇ   ‚îú‚îÄ‚îÄ email/           # Reposit√≥rio de email
‚îÇ   ‚îî‚îÄ‚îÄ persistence/     # Persist√™ncia de dados
‚îî‚îÄ‚îÄ interfaces/          # Interfaces de entrada
    ‚îú‚îÄ‚îÄ cli/            # Interface de linha de comando
    ‚îî‚îÄ‚îÄ web/            # Interface web (futuro)
```

### Padr√µes Arquiteturais

- **Clean Architecture**: Separa√ß√£o clara entre dom√≠nio, aplica√ß√£o e infraestrutura
- **Repository Pattern**: Abstra√ß√£o do acesso a dados
- **Dependency Injection**: Invers√£o de depend√™ncias
- **Strategy Pattern**: Diferentes estrat√©gias de scraping por fonte

## Fluxo de Funcionamento

### 1. Busca de Not√≠cias

```mermaid
graph TD
    A[CLI Command] --> B[NewsAggregatorUseCase]
    B --> C[WebScrapingNewsRepository]
    C --> D[BBCScraper]
    D --> E[Busca na p√°gina de resultados]
    E --> F[Extrai URLs dos artigos]
    F --> G[Busca conte√∫do completo de cada artigo]
    G --> H[Aplica filtro de relev√¢ncia]
    H --> I[Retorna not√≠cias relevantes]
```

### 2. Processo Detalhado do BBC Scraper

#### Etapa 1: Busca Inicial
```python
# URL de busca constru√≠da
url = f"https://www.bbc.com/search?q=Adam%20Sandler"

# Requisi√ß√£o HTTP com headers apropriados
async with session.get(url, headers=self.headers, timeout=30) as response:
    html = await response.text()
```

#### Etapa 2: Parsing dos Resultados
```python
# Seletores CSS para encontrar artigos
selectors = [
    '[data-testid="newport-card"]',  # Seletor principal da BBC
    'div[data-testid="search-results"] article',
    '.ssrcss-1f3bvyz-Stack',
    'article',
    '.media__content'
]
```

#### Etapa 3: Extra√ß√£o de Conte√∫do Completo
Para cada artigo encontrado:
1. Extrai t√≠tulo, URL e resumo b√°sico
2. Faz nova requisi√ß√£o HTTP para a URL do artigo
3. Extrai conte√∫do completo usando seletores espec√≠ficos:
   ```python
   content_selectors = [
       '[data-component="text-block"]',
       '.ssrcss-11r1m41-RichTextComponentWrapper',
       'div[data-component="text-block"] p',
       '.story-body__inner p'
   ]
   ```

#### Etapa 4: Filtro de Relev√¢ncia
```python
def is_relevant_to_adam_sandler(self) -> bool:
    keywords = ["adam sandler", "sandler", "happy madison", "netflix", "comedy"]
    content_to_check = f"{self.title} {self.content}".lower()
    return any(keyword in content_to_check for keyword in keywords)
```

## Entidades Principais

### News
```python
@dataclass
class News:
    title: str
    content: str
    url: str
    source: str
    published_date: datetime
    author: Optional[str] = None
    
    def is_relevant_to_adam_sandler(self) -> bool:
        # L√≥gica de filtro de relev√¢ncia
    
    def generate_summary(self) -> str:
        # Gera resumo da not√≠cia
```

### NewsSource
```python
@dataclass
class NewsSource:
    name: str
    base_url: str
    source_type: SourceType
    search_endpoint: str
    config: Dict[str, Any]
```

## Componentes T√©cnicos

### 1. BBCScraper

**Responsabilidades:**
- Buscar not√≠cias na BBC News
- Extrair conte√∫do completo dos artigos
- Aplicar filtros de relev√¢ncia

**M√©todos principais:**
- `search_adam_sandler_news()`: M√©todo principal de busca
- `_parse_search_results()`: Analisa resultados da busca
- `_extract_news_from_article()`: Extrai dados b√°sicos do artigo
- `get_article_content()`: Busca conte√∫do completo do artigo

### 2. WebScrapingNewsRepository

**Responsabilidades:**
- Gerenciar diferentes scrapers
- Coordenar sess√µes HTTP
- Remover duplicatas

**M√©todos principais:**
- `fetch_all_adam_sandler_news()`: Busca em todas as fontes
- `search_news()`: Busca por termo espec√≠fico

### 3. NewsAggregatorUseCase

**Responsabilidades:**
- Orquestrar o processo completo
- Gerar relat√≥rios
- Enviar emails

## Configura√ß√£o e Depend√™ncias

### Vari√°veis de Ambiente (.env)
```env
EMAIL_USERNAME=seu_email@gmail.com
EMAIL_PASSWORD=sua_senha_de_app
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
```

### Depend√™ncias (requirements.txt)
```
aiohttp==3.9.1
beautifulsoup4==4.12.2
python-dotenv==1.0.0
```

## Tratamento de Erros

### Estrat√©gias Implementadas

1. **Timeout de Requisi√ß√µes**: 30 segundos por requisi√ß√£o
2. **Fallback de Seletores**: M√∫ltiplos seletores CSS para robustez
3. **Tratamento de Exce√ß√µes**: Try/catch em todos os m√©todos cr√≠ticos
4. **Logs Detalhados**: Para debugging e monitoramento

### Exemplo de Tratamento
```python
try:
    async with session.get(url, headers=self.headers, timeout=30) as response:
        if response.status != 200:
            print(f"Erro ao acessar BBC: Status {response.status}")
            return []
        # ... processamento
except asyncio.TimeoutError:
    print("Timeout ao acessar BBC News")
    return []
except Exception as e:
    print(f"Erro ao buscar not√≠cias na BBC: {str(e)}")
    return []
```

## Performance e Otimiza√ß√µes

### Estrat√©gias Implementadas

1. **Sess√µes HTTP Reutiliz√°veis**: Uma sess√£o por execu√ß√£o
2. **Processamento Ass√≠ncrono**: Uso de async/await
3. **Pausa Entre Requisi√ß√µes**: 1 segundo entre fontes diferentes
4. **Limite de Resultados**: Configur√°vel por fonte

### M√©tricas T√≠picas
- Tempo m√©dio por busca: 10-15 segundos
- Artigos processados: 5-20 por execu√ß√£o
- Taxa de sucesso: >95% em condi√ß√µes normais

## Logs e Monitoramento

### Tipos de Logs

1. **Logs de Busca**: URLs constru√≠das, status HTTP
2. **Logs de Extra√ß√£o**: Seletores testados, conte√∫do encontrado
3. **Logs de Relev√¢ncia**: Filtros aplicados, resultados
4. **Logs de Erro**: Exce√ß√µes capturadas, stack traces

### Exemplo de Sa√≠da
```
URL de busca: https://www.bbc.com/search?q=Adam%20Sandler
Usando seletor '[data-testid="newport-card"]' - encontrados 9 artigos
üîç Buscando conte√∫do completo de: https://www.bbc.com/news/articles/...
‚úÖ Conte√∫do completo encontrado (2847 caracteres)
‚úÖ Not√≠cia relevante: Forbes rich list exposes Hollywood pay gap
```

## Extensibilidade

O sistema foi projetado para ser facilmente extens√≠vel:

1. **Novos Scrapers**: Implementar interface comum
2. **Novas Fontes**: Adicionar ao reposit√≥rio
3. **Novos Filtros**: Modificar l√≥gica de relev√¢ncia
4. **Novos Formatos**: Adicionar novos tipos de relat√≥rio

## Seguran√ßa

### Medidas Implementadas

1. **User-Agent Apropriado**: Simula navegador real
2. **Rate Limiting**: Pausas entre requisi√ß√µes
3. **Timeout de Seguran√ßa**: Evita travamentos
4. **Valida√ß√£o de URLs**: Verifica√ß√£o de dom√≠nios
5. **Sanitiza√ß√£o de Dados**: Limpeza de HTML

## Limita√ß√µes Conhecidas

1. **Depend√™ncia de Estrutura HTML**: Mudan√ßas no site podem quebrar scrapers
2. **Rate Limiting Externo**: Sites podem bloquear muitas requisi√ß√µes
3. **Conte√∫do Din√¢mico**: JavaScript n√£o √© executado
4. **Detec√ß√£o de Bot**: Alguns sites podem detectar automa√ß√£o

## Pr√≥ximos Passos

1. **Cache de Resultados**: Evitar requisi√ß√µes desnecess√°rias
2. **Banco de Dados**: Persist√™ncia de not√≠cias
3. **Interface Web**: Dashboard para visualiza√ß√£o
4. **Mais Fontes**: Adicionar outros sites de not√≠cias
5. **Machine Learning**: Melhorar filtros de relev√¢ncia